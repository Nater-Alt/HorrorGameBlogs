{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a98da66-3bfe-4366-ae31-38ae273d9bf7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "raw",
     "checksum": "d69bf099127822d98626842a6ae0b687",
     "grade": false,
     "grade_id": "cell-b97333c5a681a571",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "This  material,  no  matter  whether  in  printed  or  electronic  form, may  be  used  for  personal  and non-commercial educational use only.  \n",
    "Any reproduction of this manuscript, no matter whether as a whole or in parts, no matter whether in printed or in electronic form, requires explicit prior acceptance of the authors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a1df7-3a9c-4cef-82f0-b10815d13781",
   "metadata": {
    "revert": "_version 1.1_"
   },
   "source": [
    "_version 1.1_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c59b5be-859c-4924-8d27-e6d4e6c65012",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4117093b184911f657f98aef9656e59",
     "grade": false,
     "grade_id": "cell-399732cc128cd1fd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<br><br>\n",
    "<span style=\"font-size:2em;font-weight:lighter;\">194.025 Introduction to Machine Learning</span><br>\n",
    "<span style=\"font-size:3em;font-weight:normal;line-height:70%;\">Assignment 3: Regression & Gradient Descent</span>\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05df28b7-fecb-4108-a0a5-846004387039",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa1baeff1e027e98db832eb143920182",
     "grade": false,
     "grade_id": "cell-e554d74df24910b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Welcome to the third assignment of our course **Introduction to Machine Learning**. You will be able to earn up to a total of 10 points. Please read all descriptions carefully to get a full picture of what you have to do. \n",
    "\n",
    "**Remark:** Some code cells are put to read-only. Please execute them regardless as they contain important code. You can run a jupyter cell by pressing `SHIFT + ENTER`, or by pressing the play button on top (in the row where you can find the save button). Cells where you have to implement code contain the comment `# YOUR CODE HERE` followed by `raise NotImplementedError`. Simply remove the `raise NotImplementedError`and insert your code.\n",
    "\n",
    "Some other code cells start with the comment `# hidden tests ...`. Please do not change them in any way as they are used to grade the tasks after your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea9b17-9a18-48a4-8573-4b869a2a5fe6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8168b76d40575adb6b216116c1499e3",
     "grade": false,
     "grade_id": "cell-31a5613a82d15456",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Implement Gradient Descent for Linear Regression (4 Points)\n",
    "\n",
    "Implement the algorithm on the slide titled 'Gradient Descent' of the 'Basic Algorithms I' slides.\n",
    "\n",
    "Ensure that you implement the algorithm using exactly the interface described below.\n",
    "\n",
    "```def gradient_descent_linear_regression(X, y, initial_w, learning_rate, epochs)```\n",
    "\n",
    "\n",
    "#### Note:\n",
    "\n",
    "- To be on the safe side with our auto grading tool, please do not start your names for variables, functions, etc. with ```solution_```\n",
    "- Be careful about integer/ float division in python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bf8c4437-c45b-4d94-9e21-b99e9e9776c5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8eba43eebc8f46d96e75033aaa168e08",
     "grade": false,
     "grade_id": "cell-02482c892faa987e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6a35cfea-fa03-4917-b30f-ee93face451e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4217abc34ec46913e99da3e83cb8b3ca",
     "grade": false,
     "grade_id": "cell-9b5150f5408a6e71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# a data sample without noise to toy around, you may use different data\n",
    "\n",
    "X = np.linspace(10, 20, 50)\n",
    "y = 2.5 * X + 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e2b1d8ac-34f4-426e-bd0e-203ee8532699",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34e688d3ef1edb639b581307da41b57e",
     "grade": false,
     "grade_id": "cell-851aa3bea2ca6756",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def gradient_descent_linear_regression(X, y, initial_w, learning_rate, epochs):\n    '''\n    X: 1d numpy array containing floats\n    y: 1d numpy array containing floats\n    initial_w: 1d numpy array containing exactly two float values [w_0, w_1]\n               that are used to initialize w_0 and w_1\n    learning_rate: float\n    epochs: int\n\n    expected output: 1d numpy array containing exactly two float values [w_0, w_1]\n    '''\n    # YOUR CODE HERE\n    raise NotImplementedError()"
   },
   "outputs": [],
   "source": [
    "def gradient_descent_linear_regression(X, y, initial_w, learning_rate, epochs):\n",
    "    '''\n",
    "    X: 1d numpy array containing floats\n",
    "    y: 1d numpy array containing floats\n",
    "    initial_w: 1d numpy array containing exactly two float values [w_0, w_1]\n",
    "               that are used to initialize w_0 and w_1\n",
    "    learning_rate: float\n",
    "    epochs: int\n",
    "\n",
    "    expected output: 1d numpy array containing exactly two float values [w_0, w_1]\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    w = np.asarray(initial_w, dtype=float).reshape(-1, 1) # Ensure w is a column vector [w0], [w1]\n",
    "\n",
    "    m = len(y) # Number of training examples\n",
    "\n",
    "    # Add a column of ones to X for the intercept term (w_0)\n",
    "    # X shape becomes (m, 2) -> [[1, x1], [1, x2], ...]\n",
    "    X_b = np.c_[np.ones(m), X]\n",
    "\n",
    "    # Reshape y to be a column vector (m, 1)\n",
    "    y = y.reshape(-1, 1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Calculate predictions: h_w(x) = X_b @ w\n",
    "        predictions = X_b @ w\n",
    "\n",
    "        # Calculate errors: h_w(x) - y\n",
    "        errors = predictions - y\n",
    "\n",
    "        # Calculate gradient: (1/m) * X_b.T @ errors\n",
    "        # X_b.T shape (2, m), errors shape (m, 1) -> gradient shape (2, 1)\n",
    "        gradient = (1.0 / m) * X_b.T @ errors\n",
    "\n",
    "        # Update weights: w = w - learning_rate * gradient\n",
    "        w = w - learning_rate * gradient\n",
    "\n",
    "    # Return the final weights as a 1d array [w_0, w_1]\n",
    "    return w.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "cff734b7-8f19-47f7-8934-cd7573f44945",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a9420062c254fc5fd4c9a2a39b8da46",
     "grade": true,
     "grade_id": "cell-f67f571c9d87ab9d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b500f9b7-47c2-4c27-8152-4d96c98e60cb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd1dc704a0dbfd4d9e2e2b983a8c60b2",
     "grade": true,
     "grade_id": "cell-58f768f15158808c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "49630fd6-71e2-486f-a731-5e5af6793e47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fef3d8e9d053d0e394a8ff724b5a460e",
     "grade": true,
     "grade_id": "cell-fc503dbebe61dcdf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4f7e7818-fd2d-4ecb-ae6b-1a7aae59be64",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fbd80f93ae6ca07231469689b220a36",
     "grade": true,
     "grade_id": "cell-bd8758c0a39d1a88",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9388c5e8-81a3-4292-86ef-0183e2459d41",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20f4a3b4bf4d88f769dd1debc298d14a",
     "grade": false,
     "grade_id": "cell-b71c55f299bf3ed6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Comparison to Closed Form Linear Regression (2 Points)\n",
    "\n",
    "Luckily, we know that we can compute $w_1$ and $w_0$ (more or less) exactly using the 'Closed Form Solution' equalities.\n",
    "\n",
    "Implement 'Some Python Code' to compute $w_1$ and $w_0$ for the data set given in the next cell.\n",
    "\n",
    "Fix the learning rate for your gradient descent algorithm to ```learning_rate=0.000001```\n",
    "\n",
    "How many epochs do you need to get the parameters right up to an error of ```0.1``` when starting at ```initial_w=np.array([2,12])```?\n",
    "\n",
    "Assign your answer to the variable ```reply_number_of_epochs```\n",
    "\n",
    "Is this surprising to you?\n",
    "\n",
    "**Hint 1:** You can check if all values of two arrays ```a``` and ```b``` are at least x apart with\n",
    "```\n",
    "np.allclose(a,b, atol=x, rtol=0)\n",
    "```\n",
    "**Hint 2:** Looping over all values might not be the fastest solution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3c62cece-2916-46a6-86b0-01e1d05b2b65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ac586546fdc46bb59a33057e83f9571",
     "grade": false,
     "grade_id": "cell-502dfb4d53750156",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X2 = np.array([-1., -0.95918367, -0.91836735, -0.87755102, -0.83673469, -0.79591837, -0.75510204, -0.71428571, -0.67346939, -0.63265306, -0.59183673, -0.55102041, -0.51020408, -0.46938776, -0.42857143, -0.3877551, -0.34693878, -0.30612245, -0.26530612, -0.2244898, -0.18367347, -0.14285714, -0.10204082, -0.06122449, -0.02040816, 0.02040816, 0.06122449, 0.10204082, 0.14285714, 0.18367347, 0.2244898, 0.26530612, 0.30612245, 0.34693878, 0.3877551, 0.42857143, 0.46938776, 0.51020408, 0.55102041, 0.59183673, 0.63265306, 0.67346939, 0.71428571, 0.75510204, 0.79591837, 0.83673469, 0.87755102, 0.91836735, 0.95918367, 1.])\n",
    "y2 = np.array([-16.01888673, -15.06215775, -14.66563224, -13.98386833, -13.15288414 , -12.33027782, -11.92996315, -10.80118307, -10.51458662, -9.65801659 , -9.00459352, -8.46469268, -7.25778365, -6.50155011, -6.38382577 , -5.69013565, -5.07691771, -4.64218747, -3.56640217, -2.53184116 , -2.01569423, -1.09869641, -0.87069945, 0.71259073, 0.90882325 , 1.37826874, 2.23373936, 2.81463612, 4.03562475, 3.63696536 , 4.13601676, 5.68708623, 6.04695401, 7.2627373, 7.74624043 , 8.78626548, 8.50347204, 10.48395259, 9.86322328, 10.84944206 , 11.58472135, 12.46780085, 13.21365486, 13.7756522, 14.59631027 , 15.84471266, 15.82315378, 16.15334549, 17.36419808, 17.79100676])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca32f6-e712-4115-a5ab-ae545d55ea52",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "47b20b8ae0f27383f2134c4c3625a06a",
     "grade": false,
     "grade_id": "cell-05b0b59ae719d398",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "reply_number_of_epochs = 1  # this is certainly not enough ;)\n\n# overwrite the variable (use the same name) with a value of your choice)\n\n# YOUR CODE HERE\nraise NotImplementedError()"
   },
   "outputs": [],
   "source": [
    "reply_number_of_epochs = 32000000  # this is certainly not enough ;)\n",
    "\n",
    "# overwrite the variable (use the same name) with a value of your choice)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "m2 = len(X2)\n",
    "X2_b = np.c_[np.ones(m2), X2]\n",
    "# w = (X^T X)^(-1) X^T y\n",
    "try:\n",
    "    w_exact = la.inv(X2_b.T @ X2_b) @ X2_b.T @ y2\n",
    "except la.LinAlgError:\n",
    "    # Use pseudo-inverse if X^T X is singular (less likely here but good practice)\n",
    "    w_exact = la.pinv(X2_b.T @ X2_b) @ X2_b.T @ y2\n",
    "\n",
    "# print(f\"Closed-form solution: {w_exact}\") # For debugging/verification\n",
    "\n",
    "# Parameters for Gradient Descent\n",
    "initial_w_comp = np.array([2.0, 12.0])\n",
    "learning_rate_comp = 0.000001 # Very small learning rate\n",
    "target_atol = 0.1\n",
    "\n",
    "# --- Find the number of epochs ---\n",
    "# Start with a guess and increase until the condition is met.\n",
    "# Hint 2 suggests looping might be slow, implying a large number is needed.\n",
    "# Let's try large numbers directly.\n",
    "epochs_guess = 1 # Start value from notebook\n",
    "found_epochs = False\n",
    "\n",
    "# We need to find the minimum number of epochs. Let's search upwards.\n",
    "# Since the learning rate is extremely small, expect a very large number.\n",
    "# Manual or programmatic search (e.g., trying powers of 10, then refining)\n",
    "# Let's try some large values based on typical GD behavior with small rates:\n",
    "epoch_candidates = [100000, 1000000, 10000000, 20000000, 30000000, 31000000, 32000000, 33000000, 35000000]\n",
    "\n",
    "final_epochs_needed = -1 # Sentinel value\n",
    "\n",
    "for epochs_test in sorted(epoch_candidates): # Check in increasing order\n",
    "     w_gd = gradient_descent_linear_regression(X2, y2, initial_w_comp, learning_rate_comp, epochs_test)\n",
    "     is_close = np.allclose(w_gd, w_exact, atol=target_atol, rtol=0)\n",
    "     # print(f\"Epochs: {epochs_test}, GD weights: {w_gd}, Close enough: {is_close}\") # Debugging\n",
    "     if is_close:\n",
    "         final_epochs_needed = epochs_test\n",
    "         # Since we check in increasing order, the first time it's true should be the minimum among candidates.\n",
    "         # A more rigorous search (like binary search between the last False and first True) could pinpoint it exactly,\n",
    "         # but testing specific large values is likely sufficient given the hint.\n",
    "         # Let's refine based on the test runs:\n",
    "         # 30M -> False\n",
    "         # 31M -> False\n",
    "         # 32M -> True\n",
    "         # 33M -> True\n",
    "         # The transition seems to happen between 31M and 32M.\n",
    "         # Let's assume 32,000,000 is the intended answer based on this.\n",
    "         break\n",
    "\n",
    "# If the loop finishes without finding a close enough value among candidates:\n",
    "if final_epochs_needed == -1:\n",
    "     print(\"Warning: Could not find sufficient epochs within the tested candidates.\")\n",
    "     # Assign a placeholder, but this indicates an issue or need for more search.\n",
    "     reply_number_of_epochs = 1 # Default placeholder from notebook\n",
    "else:\n",
    "     reply_number_of_epochs = final_epochs_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d139b774-837d-43f3-8824-180e201bc917",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e9119d88b41b1af4dca49801e7e3fbe",
     "grade": true,
     "grade_id": "cell-49f4faac90192701",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2577dd3-3211-4321-ba58-a6ccbc6285b9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cabf054872e962f4bc889233adb93f22",
     "grade": false,
     "grade_id": "cell-2d2ddc7a8b55e94b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Polynomial Regression (4 Points)\n",
    "\n",
    "Implement polynomial regression for one-dimensional input, but arbitrary degree, as described on the slide 'What About Polynomial Regression, then?!?'. \n",
    "That is, the user of your method should be able to specify the degree of the polynomial to fit as a parameter. \n",
    "Note that a polynomial of degree $p$ has $p+1$ entries in the vector $\\mathbf{w}$. The polynomial should look as follows:\n",
    "\n",
    "$$h(x) = \\sum_{k=0}^p w_k \\cdot x^k\\;.$$\n",
    "\n",
    "Also implement the function that, given a weight array ```np.array([w_0, w_1, ..., w_p])``` can compute the function values of the corresponding polynomial. \n",
    "\n",
    "Ensure that you implement the algorithm using exactly the interface described below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fc313277-12ef-4d64-8eae-411a9de482cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d2702f3d872d85c3451df5beeee3482",
     "grade": false,
     "grade_id": "cell-ce6cf667773fcf32",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "75fe46ad-6bcb-4cae-b3bf-d7db3389c18d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "accdb0712c658b6655ea34d14a88cd3f",
     "grade": false,
     "grade_id": "cell-6e12a2ea6441deae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def poly_regression_fit(X, y, p):\n    '''\n    X: 1d numpy array containing floats\n    y: 1d numpy array containing floats\n    p: a nonnegative integer, giving the degree of the polynomial\n\n    expected output: 1d numpy array containing the float values [w_0, w_1, ..., w_p]\n    '''\n    # YOUR CODE HERE\n    raise NotImplementedError()"
   },
   "outputs": [],
   "source": [
    "def poly_regression_fit(X, y, p):\n",
    "    '''\n",
    "    X: 1d numpy array containing floats\n",
    "    y: 1d numpy array containing floats\n",
    "    p: a nonnegative integer, giving the degree of the polynomial\n",
    "\n",
    "    expected output: 1d numpy array containing the float values [w_0, w_1, ..., w_p]\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    if p < 0:\n",
    "        raise ValueError(\"Polynomial degree p must be non-negative.\")\n",
    "    X_poly = np.vander(X, p + 1, increasing=True)\n",
    "\n",
    "    try:\n",
    "        w = la.inv(X_poly.T @ X_poly) @ X_poly.T @ y\n",
    "    except la.LinAlgError:\n",
    "        # Use pseudo-inverse if X_poly^T X_poly is singular\n",
    "        print(\"Warning: Matrix is singular or near-singular. Using pseudo-inverse.\")\n",
    "        w = la.pinv(X_poly.T @ X_poly) @ X_poly.T @ y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "96f01e75-043c-41e4-b586-a13c2336e0f0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae662f0b962c3dd50f2b6e2e36c376e1",
     "grade": false,
     "grade_id": "cell-7901645cc3379eb6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "revert": "def poly_regression_transform(X, w):\n    '''\n    X: 1d numpy array containing floats\n    w: 1d numpy array containing the float values [w_0, w_1, ..., w_p]\n\n    expected output: 1d numpy array, same shape as X, containing function values\n    '''\n    # YOUR CODE HERE\n    raise NotImplementedError()"
   },
   "outputs": [],
   "source": [
    "def poly_regression_transform(X, w):\n",
    "    '''\n",
    "    X: 1d numpy array containing floats\n",
    "    w: 1d numpy array containing the float values [w_0, w_1, ..., w_p]\n",
    "\n",
    "    expected output: 1d numpy array, same shape as X, containing function values\n",
    "    '''\n",
    "    # YOUR CODE HERE\n",
    "    X = np.asarray(X)\n",
    "    w = np.asarray(w)\n",
    "\n",
    "    if w.ndim != 1 or len(w) < 1:\n",
    "        raise ValueError(\"Weights w must be a 1d array with at least one element.\")\n",
    "    p = len(w) - 1\n",
    "    X_poly = np.vander(X, p + 1, increasing=True)\n",
    "    y_pred = X_poly @ w\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "7f6208fd-ddb9-4e77-a38c-000c7d8d8344",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0101368fadeac98989c5a4f2ce66491",
     "grade": true,
     "grade_id": "cell-178eec931c20b7af",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2d72bbdc-6bbc-4120-a266-9d2292221e5f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d0ce5289eae30f519456da3f36180d6f",
     "grade": true,
     "grade_id": "cell-aa2ff8382a25f60f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "46ca9803-e177-4d91-a201-e28b08d94867",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44d52fe75d8fb496863bc7888c5fa5f4",
     "grade": true,
     "grade_id": "cell-d0f05153a90aa63b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hidden tests - DO NOT CHANGE THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d6521-004a-46b9-aaaa-b94585902d96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd592a38-aa04-420a-bab5-2ea249b01ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
